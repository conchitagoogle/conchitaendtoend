{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cebabe4",
   "metadata": {},
   "source": [
    "# 3 - Vertex AI > Pipelines - AutoML with clients (code) In automated pipeline\n",
    "\n",
    "Use[ Kubeflow](https://www.kubeflow.org/) Pipelines running on [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) to orchestrate the process of training a custom model with AutoML Tabular and deploy it to a Vertex AI Endpoint for serving (online and batch) predictions and explanations.  This demonstrates how to automate the processes of (02a) or (02b) with pipeline orchestration.\n",
    "\n",
    "\n",
    "\n",
    "### Prerequisites:\n",
    "-  01 -  BigQuery - Table Data Source\n",
    "\n",
    "### Overview:\n",
    "-  Use Kubeflow Python SDK to build a pipeline\n",
    "   -  Create pipeline using Google Cloud Pipeline Components (from google_cloud_pipeline_components import aiplatform as gcc_aip)\n",
    "      -  Use cc_aip.TabularDatasetCreateOp to register dataset from BigQuery table\n",
    "      -  Train AutoML tabular model with gcc_aip.AutoMLTabularTrainingJobRunOp\n",
    "      -  Deploy model to endpoint using gcc_aip.ModelDeployOp\n",
    "   -  Compile the pipeline\n",
    "      -  kfp.v2.compiler.Compiler().compile\n",
    "   -  Move the pipeline code to GCS Bucket\n",
    "   -  Run the pipeline with google.cloud.aiplatform.PipelineJob\n",
    "-  Online Predictions using Vertex AI Endpoint\n",
    "-  Online Explanations using Vertex AI Endpoint\n",
    "-  Batch Prediction Job for predictions and explanation with source and destination tables in BigQuery\n",
    "\n",
    "### Resources:\n",
    "-  [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline#google-cloud-components) see aiplatform.PipelineJob\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  [Kubeflow Pipelines Components for Google Cloud](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cef71",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b82e4",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b255bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "PROJECT_ID='qwiklabs-gcp-04-24efb7132888'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '3'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00693f36",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bf8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import kfp\n",
    "#import kfp.v2.dsl as dsl\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a4860",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f88c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bigquery = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14fbbc",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f65b2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = \"conchitademomlopsendtoend\"\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c636bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'948421954571-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give service account roles/storage.objectAdmin permissions\n",
    "# Console > IMA > Select Account <projectnumber>-compute@developer.gserviceaccount.com > edit - give role\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f15187",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7383876",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c3499",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline (KFP) Definition\n",
    "- Flow\n",
    "    - Create Vertex AI Dataset from link to BigQuery table\n",
    "    - Create Vertex AI AutoML Tabular Training Job\n",
    "    - Create Endpoint and Depoy trained model\n",
    "    \n",
    "Use [AI Platform Pipeline Components](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/)\n",
    "- Specifically, [AutoMLTabularTrainingJobRunOp](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.AutoMLTabularTrainingJobRunOp)\n",
    "\n",
    "Define a Job:\n",
    "- Consider Weighting\n",
    "- Model Type\n",
    "- Optimization Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb85abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name = f'kfp-{NOTEBOOK}-{DATANAME}-{TIMESTAMP}', pipeline_root = URI+'/'+str(TIMESTAMP)+'/kfp/')\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    dataname: str = DATANAME,\n",
    "    display_name: str = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    deploy_machine: str = DEPLOY_COMPUTE,\n",
    "    bq_source: str = f'bq://{PROJECT_ID}.{DATANAME}.{DATANAME}_prepped',\n",
    "    var_target: str = VAR_TARGET,\n",
    "    var_omit: str = VAR_OMIT,\n",
    "    label: str = NOTEBOOK \n",
    "):\n",
    "    \n",
    "    # dataset\n",
    "    dataset = gcc_aip.TabularDatasetCreateOp(\n",
    "        project = project,\n",
    "        display_name = display_name,\n",
    "        bq_source = bq_source,\n",
    "        #labels = {'notebook':f'{label}'}\n",
    "    )\n",
    "    \n",
    "    # get feature names\n",
    "    from google.cloud import bigquery\n",
    "    bigquery = bigquery.Client(project = PROJECT_ID)\n",
    "    query = f\"SELECT * FROM {DATANAME}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{DATANAME}_prepped'\"\n",
    "    schema = bigquery.query(query).to_dataframe()\n",
    "    OMIT = VAR_OMIT.split() + [VAR_TARGET, 'splits']\n",
    "    features = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
    "    features = dict.fromkeys(features, 'auto')\n",
    "    \n",
    "    # training\n",
    "    model = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project = project,\n",
    "        display_name = display_name,\n",
    "        optimization_prediction_type = \"classification\",\n",
    "        optimization_objective = \"maximize-au-prc\",\n",
    "        budget_milli_node_hours = 1000,\n",
    "        disable_early_stopping=False,\n",
    "        column_specs = features,\n",
    "        dataset = dataset.outputs['dataset'],\n",
    "        target_column = var_target,\n",
    "        predefined_split_column_name = 'splits',\n",
    "        #labels = {'notebook':f'{label}'}\n",
    "    )\n",
    "    \n",
    "    # Endpoint: Creation\n",
    "    endpoint = gcc_aip.EndpointCreateOp(\n",
    "        project = project,\n",
    "        display_name = display_name,\n",
    "        #labels = {'notebook':f'{label}'}\n",
    "    )\n",
    "    \n",
    "    # Endpoint: Deployment of Model\n",
    "    deployment = gcc_aip.ModelDeployOp(\n",
    "        model = model.outputs[\"model\"],\n",
    "        endpoint = endpoint.outputs[\"endpoint\"],\n",
    "        dedicated_resources_min_replica_count = 1,\n",
    "        dedicated_resources_max_replica_count = 1,\n",
    "        traffic_split = {\"0\": 100},\n",
    "        dedicated_resources_machine_type= deploy_machine\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7cda6",
   "metadata": {},
   "source": [
    "---\n",
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db3e8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f\"{DIR}/{NOTEBOOK}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3a04e",
   "metadata": {},
   "source": [
    "Move compiled pipeline files to GCS Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671d4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://temp/3/3.json [Content-Type=application/json]...\n",
      "/ [1 files][ 23.4 KiB/ 23.4 KiB]                                                \n",
      "Operation completed over 1 objects/23.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {DIR}/{NOTEBOOK}.json {URI}/{TIMESTAMP}/kfp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45241ff1",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Vertex AI Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5dd3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    template_path = f\"{URI}/{TIMESTAMP}/kfp/{NOTEBOOK}.json\",\n",
    "    pipeline_root = f\"{URI}/{TIMESTAMP}/kfp/\",\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ee521df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/kfp-3-fraud-20220320113933-20220320115351?project=948421954571\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/948421954571/locations/us-central1/pipelineJobs/kfp-3-fraud-20220320113933-20220320115351\n"
     ]
    }
   ],
   "source": [
    "response = pipeline.run(service_account = SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ff7495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:var_target</th>\n",
       "      <th>param.input:deploy_machine</th>\n",
       "      <th>param.input:display_name</th>\n",
       "      <th>param.input:label</th>\n",
       "      <th>param.input:bq_source</th>\n",
       "      <th>param.input:var_omit</th>\n",
       "      <th>param.input:dataname</th>\n",
       "      <th>param.input:project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kfp-3-fraud-20220320113933</td>\n",
       "      <td>kfp-3-fraud-20220320113933-20220320115351</td>\n",
       "      <td>Class</td>\n",
       "      <td>n1-standard-4</td>\n",
       "      <td>3_fraud_20220320113933</td>\n",
       "      <td>3</td>\n",
       "      <td>bq://qwiklabs-gcp-04-24efb7132888.fraud.fraud_...</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>fraud</td>\n",
       "      <td>qwiklabs-gcp-04-24efb7132888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kfp-3-fraud-20220320113933</td>\n",
       "      <td>kfp-3-fraud-20220320113933-20220320115030</td>\n",
       "      <td>Class</td>\n",
       "      <td>n1-standard-4</td>\n",
       "      <td>3_fraud_20220320113933</td>\n",
       "      <td>3</td>\n",
       "      <td>bq://qwiklabs-gcp-04-24efb7132888.fraud.fraud_...</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>fraud</td>\n",
       "      <td>qwiklabs-gcp-04-24efb7132888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kfp-3-fraud-20220320113933</td>\n",
       "      <td>kfp-3-fraud-20220320113933-20220320113943</td>\n",
       "      <td>Class</td>\n",
       "      <td>n1-standard-4</td>\n",
       "      <td>3_fraud_20220320113933</td>\n",
       "      <td>3</td>\n",
       "      <td>bq://qwiklabs-gcp-04-24efb7132888.fraud.fraud_...</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>fraud</td>\n",
       "      <td>qwiklabs-gcp-04-24efb7132888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pipeline_name                                   run_name  \\\n",
       "0  kfp-3-fraud-20220320113933  kfp-3-fraud-20220320113933-20220320115351   \n",
       "1  kfp-3-fraud-20220320113933  kfp-3-fraud-20220320113933-20220320115030   \n",
       "2  kfp-3-fraud-20220320113933  kfp-3-fraud-20220320113933-20220320113943   \n",
       "\n",
       "  param.input:var_target param.input:deploy_machine param.input:display_name  \\\n",
       "0                  Class              n1-standard-4   3_fraud_20220320113933   \n",
       "1                  Class              n1-standard-4   3_fraud_20220320113933   \n",
       "2                  Class              n1-standard-4   3_fraud_20220320113933   \n",
       "\n",
       "  param.input:label                              param.input:bq_source  \\\n",
       "0                 3  bq://qwiklabs-gcp-04-24efb7132888.fraud.fraud_...   \n",
       "1                 3  bq://qwiklabs-gcp-04-24efb7132888.fraud.fraud_...   \n",
       "2                 3  bq://qwiklabs-gcp-04-24efb7132888.fraud.fraud_...   \n",
       "\n",
       "  param.input:var_omit param.input:dataname           param.input:project  \n",
       "0       transaction_id                fraud  qwiklabs-gcp-04-24efb7132888  \n",
       "1       transaction_id                fraud  qwiklabs-gcp-04-24efb7132888  \n",
       "2       transaction_id                fraud  qwiklabs-gcp-04-24efb7132888  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'kfp-{NOTEBOOK}-{DATANAME}-{TIMESTAMP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523ffaa-9dfb-41cb-b7b5-6cc6ddae1613",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Evaluation\n",
    "While the model above was trained using AutoML with the API, it is still possible to review the evaluation metrics directly in the Google Cloud Console.  Just visit the Models section of Vertex AI service and select the model and it will present the evaluation metrics with many helpful visuals.\n",
    "\n",
    "It is also possible to retrieve the evaluation metrics for you model using the API.  This section shows how to use the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1c3f1",
   "metadata": {},
   "source": [
    "Get the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6634c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aiplatform.Model.list(filter=f'display_name={NOTEBOOK}_{DATANAME}_{TIMESTAMP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106b740-1d3b-43b5-ac3d-311fb298b2bf",
   "metadata": {},
   "source": [
    "Setup a model client for the model create by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4f7b61b-ad0f-487b-8dc6-ac8ed12e6afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/948421954571/locations/us-central1/models/4135733823042224128'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02bbdfaa-75dc-4482-8781-d73f0043aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = aiplatform.gapic.ModelServiceClient(\n",
    "    client_options = {\n",
    "        'api_endpoint' : f'{REGION}-aiplatform.googleapis.com'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71227e04-8bb0-46d5-862e-3fddfe0361ae",
   "metadata": {},
   "source": [
    "Retrives the aggregate model evalution metrics for the model as a whole.  First, use `.list_model_evaluations` to retrieve the evaluation id, then use `.get_model_evaluation` for the evaluation id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "974b597e-f01d-4147-a824-9a6ac8246a1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'resource_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23666/2303005028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_model_evaluations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgeteval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'resource_name'"
     ]
    }
   ],
   "source": [
    "evaluations = model_client.list_model_evaluations(parent = model.resource_name)\n",
    "evals = iter(evaluations)\n",
    "eval_id = next(evals).name\n",
    "geteval = model_client.get_model_evaluation(name = eval_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa9551-2e4a-4673-b0d5-1ddec1233e0e",
   "metadata": {},
   "source": [
    "Review several of the metrics include in the evaluation.  Also, compare these to the results in the console view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6e04f-c0ec-4ad1-a8be-460cddcb0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "geteval.metrics['auPrc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9892b-eeac-4a64-aa9b-68a7a45a3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(geteval.metrics['confusionMatrix']['annotationSpecs'])):\n",
    "    print('True Label = ', geteval.metrics['confusionMatrix']['annotationSpecs'][i]['displayName'], ' has Predicted labels = ', geteval.metrics['confusionMatrix']['rows'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266afe6-be3f-4565-afd9-cb839682df2c",
   "metadata": {},
   "source": [
    "For models with labels you can retrieve the evaluation metrics for each slice of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a6f0d-ab29-4825-a29e-335f5a1727e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = model_client.list_model_evaluation_slices(parent = eval_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b5c5a-d43c-4c77-8806-fa92f6438e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice in slices:\n",
    "    print('Label = ', slice.slice_.value, 'has auPrc = ', slice.metrics['auPrc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829782e",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269e25d",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bigquery.query(query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "#newob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fde74e",
   "metadata": {},
   "source": [
    "Need to understand the format of variables that the predictions expect.  AutoML may convert the type of some variables. The following cells retrieve the model from the endpoint and its schemata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newob['Time'] = str(newob['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value())]\n",
    "parameters = json_format.ParseDict({}, Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61f206",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fefd9-e7c7-4971-8e6b-d630469f2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.Endpoint.list(filter=f'display_name={NOTEBOOK}_{DATANAME}_{TIMESTAMP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279cf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.list(filter=f'display_name={NOTEBOOK}_{DATANAME}_{TIMESTAMP}')[0]\n",
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c298d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances=instances, parameters=parameters)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predictions[0]['classes'][np.argmax(prediction.predictions[0]['scores'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68781f2",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b428c9d",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3523017",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d825b",
   "metadata": {},
   "source": [
    "---\n",
    "## Explanations\n",
    "Interpretation Guide\n",
    "- https://cloud.google.com/vertex-ai/docs/predictions/interpreting-results-automl#tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80280fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = endpoint.explain(instances=instances, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"attribution:\")\n",
    "print(\"baseline output\",explanation.explanations[0].attributions[0].baseline_output_value)\n",
    "print(\"instance output\",explanation.explanations[0].attributions[0].instance_output_value)\n",
    "print(\"output_index\",explanation.explanations[0].attributions[0].output_index)\n",
    "print(\"output display value\",explanation.explanations[0].attributions[0].output_display_name)\n",
    "print(\"approximation error\",explanation.explanations[0].attributions[0].approximation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdc889-9620-4e5c-adf9-5ecf2238ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "features = []\n",
    "scores = []\n",
    "for k in explanation.explanations[0].attributions[0].feature_attributions:\n",
    "    features.append(k)\n",
    "    scores.append(explanation.explanations[0].attributions[0].feature_attributions[k])\n",
    "features = [x for _, x in sorted(zip(scores, features))]\n",
    "scores = sorted(scores)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9, 9)\n",
    "ax.barh(features, scores)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12e906",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch Predictions: BigQuery Source to BigQuery Destination, with Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = aiplatform.BatchPredictionJob.create(\n",
    "    job_display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    model_name = endpoint.list_models()[0].model,\n",
    "    instances_format = \"bigquery\",\n",
    "    predictions_format = \"bigquery\",\n",
    "    bigquery_source = f'bq://{PROJECT_ID}.{DATANAME}.{DATANAME}_prepped',\n",
    "    bigquery_destination_prefix = f\"{PROJECT_ID}\",\n",
    "    generate_explanation=True,\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded790f-c809-45bd-9882-5e729164a277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
